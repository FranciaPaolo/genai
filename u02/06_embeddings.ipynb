{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-13 21:16:27.181722: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-13 21:16:27.772355: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-13 21:16:27.772653: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-13 21:16:27.865790: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-13 21:16:28.066061: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-09-13 21:16:28.069054: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-13 21:16:30.211813: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = ['the glass of milk',\n",
    "        'the glass of juice',\n",
    "        'the cup of tea',\n",
    "        'I am a good boy',\n",
    "        'I am a good developer',\n",
    "        'understand the meaning of words',\n",
    "        'your videos are good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the vocabulary size\n",
    "voc_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5902, 8077, 8575, 2529],\n",
       " [5902, 8077, 8575, 2853],\n",
       " [5902, 6809, 8575, 1306],\n",
       " [9967, 5181, 4100, 7243, 6233],\n",
       " [9967, 5181, 4100, 7243, 1388],\n",
       " [8756, 5902, 8179, 8575, 8761],\n",
       " [9323, 6862, 3040, 7243]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One hot representation\n",
    "one_hot_repr=[one_hot(word,voc_size) for word in sent]\n",
    "one_hot_repr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding representation\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0 5902 8077 8575 2529]\n",
      " [   0    0    0    0 5902 8077 8575 2853]\n",
      " [   0    0    0    0 5902 6809 8575 1306]\n",
      " [   0    0    0 9967 5181 4100 7243 6233]\n",
      " [   0    0    0 9967 5181 4100 7243 1388]\n",
      " [   0    0    0 8756 5902 8179 8575 8761]\n",
      " [   0    0    0    0 9323 6862 3040 7243]]\n"
     ]
    }
   ],
   "source": [
    "# padding to have sentences of the same lenght\n",
    "\n",
    "sent_length=8 # rounded up from the number of words in the list of sentences above\n",
    "embedded_docs=pad_sequences(one_hot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature representation\n",
    "dim=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sent_length: 8, voc_size: 10000\n"
     ]
    }
   ],
   "source": [
    "# features are the possible classification of each word (ex. male, age, food, ...)s\n",
    "model=Sequential()\n",
    "model.add(Embedding(voc_size,dim,input_length=sent_length))\n",
    "model.compile('adam','mse')\n",
    "\n",
    "print(f\"sent_length: {sent_length}, voc_size: {voc_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 8, 10)             100000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100000 (390.62 KB)\n",
      "Trainable params: 100000 (390.62 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [-0.04750576,  0.02172827, -0.02922004,  0.03455141,\n",
       "          0.02342845, -0.00144625, -0.00692127, -0.03872278,\n",
       "         -0.02435346,  0.03033866],\n",
       "        [-0.03073707,  0.02286344,  0.03730031, -0.01533101,\n",
       "         -0.02043747,  0.01430011, -0.00907749, -0.00447345,\n",
       "          0.02035972,  0.00047056],\n",
       "        [-0.02976832, -0.01871274, -0.00634702,  0.04747427,\n",
       "         -0.03089167,  0.03714018, -0.00384187, -0.01120083,\n",
       "          0.03585826,  0.0158645 ],\n",
       "        [ 0.04272357, -0.01344483,  0.021655  , -0.00197617,\n",
       "         -0.00738341, -0.0367843 ,  0.01925168, -0.01786853,\n",
       "         -0.01657099, -0.04147851]],\n",
       "\n",
       "       [[ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [-0.04750576,  0.02172827, -0.02922004,  0.03455141,\n",
       "          0.02342845, -0.00144625, -0.00692127, -0.03872278,\n",
       "         -0.02435346,  0.03033866],\n",
       "        [-0.03073707,  0.02286344,  0.03730031, -0.01533101,\n",
       "         -0.02043747,  0.01430011, -0.00907749, -0.00447345,\n",
       "          0.02035972,  0.00047056],\n",
       "        [-0.02976832, -0.01871274, -0.00634702,  0.04747427,\n",
       "         -0.03089167,  0.03714018, -0.00384187, -0.01120083,\n",
       "          0.03585826,  0.0158645 ],\n",
       "        [ 0.01781715,  0.01007487,  0.01654859,  0.00592045,\n",
       "         -0.02831514, -0.00483334,  0.02921904,  0.00691523,\n",
       "          0.00627952,  0.01321865]],\n",
       "\n",
       "       [[ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [-0.04750576,  0.02172827, -0.02922004,  0.03455141,\n",
       "          0.02342845, -0.00144625, -0.00692127, -0.03872278,\n",
       "         -0.02435346,  0.03033866],\n",
       "        [ 0.02957643, -0.03551061,  0.00734935, -0.01317941,\n",
       "         -0.00693054, -0.02228372, -0.04930362, -0.02605703,\n",
       "         -0.04991273,  0.04757965],\n",
       "        [-0.02976832, -0.01871274, -0.00634702,  0.04747427,\n",
       "         -0.03089167,  0.03714018, -0.00384187, -0.01120083,\n",
       "          0.03585826,  0.0158645 ],\n",
       "        [ 0.04441652,  0.0004307 ,  0.04687211,  0.03853485,\n",
       "          0.04560233, -0.00449635,  0.02367038,  0.00103591,\n",
       "         -0.03676196,  0.02265709]],\n",
       "\n",
       "       [[ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.02490709,  0.00322273, -0.00358514, -0.03077483,\n",
       "         -0.04244503, -0.03076454,  0.00393848, -0.02006399,\n",
       "          0.00956102, -0.01024275],\n",
       "        [ 0.04382094,  0.02805041,  0.03327056,  0.00424483,\n",
       "          0.01461696,  0.03644911,  0.01187104,  0.00566348,\n",
       "          0.00667534, -0.01906922],\n",
       "        [ 0.04229086, -0.04433311, -0.0392948 , -0.04986538,\n",
       "          0.00977314, -0.04072483,  0.02996457, -0.00122588,\n",
       "          0.00893396,  0.00792171],\n",
       "        [ 0.02756012,  0.03659394, -0.04558331,  0.04542447,\n",
       "         -0.03317118, -0.04099707,  0.02059417, -0.00535005,\n",
       "          0.02082281, -0.03791739],\n",
       "        [-0.01309506, -0.00728504,  0.02615226,  0.04346441,\n",
       "         -0.04582096, -0.03612521, -0.0017633 , -0.02389869,\n",
       "         -0.02137738, -0.00218783]],\n",
       "\n",
       "       [[ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.02490709,  0.00322273, -0.00358514, -0.03077483,\n",
       "         -0.04244503, -0.03076454,  0.00393848, -0.02006399,\n",
       "          0.00956102, -0.01024275],\n",
       "        [ 0.04382094,  0.02805041,  0.03327056,  0.00424483,\n",
       "          0.01461696,  0.03644911,  0.01187104,  0.00566348,\n",
       "          0.00667534, -0.01906922],\n",
       "        [ 0.04229086, -0.04433311, -0.0392948 , -0.04986538,\n",
       "          0.00977314, -0.04072483,  0.02996457, -0.00122588,\n",
       "          0.00893396,  0.00792171],\n",
       "        [ 0.02756012,  0.03659394, -0.04558331,  0.04542447,\n",
       "         -0.03317118, -0.04099707,  0.02059417, -0.00535005,\n",
       "          0.02082281, -0.03791739],\n",
       "        [-0.01039678, -0.03711312, -0.0335004 ,  0.03512606,\n",
       "         -0.049602  , -0.04412348,  0.0020442 , -0.01413519,\n",
       "         -0.03079618, -0.04595165]],\n",
       "\n",
       "       [[ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.00931435, -0.03638742, -0.03961718,  0.04045611,\n",
       "         -0.00522541,  0.01513268,  0.02689458,  0.02999732,\n",
       "          0.03297753,  0.00211378],\n",
       "        [-0.04750576,  0.02172827, -0.02922004,  0.03455141,\n",
       "          0.02342845, -0.00144625, -0.00692127, -0.03872278,\n",
       "         -0.02435346,  0.03033866],\n",
       "        [-0.00403997, -0.01682526, -0.02243391,  0.01478812,\n",
       "          0.04860809, -0.02598666, -0.02612729, -0.01421462,\n",
       "         -0.01742163, -0.00591755],\n",
       "        [-0.02976832, -0.01871274, -0.00634702,  0.04747427,\n",
       "         -0.03089167,  0.03714018, -0.00384187, -0.01120083,\n",
       "          0.03585826,  0.0158645 ],\n",
       "        [-0.04153197,  0.00927661,  0.04309795, -0.04310229,\n",
       "         -0.0099792 ,  0.01053854, -0.03505041,  0.0336454 ,\n",
       "          0.03268332, -0.04884821]],\n",
       "\n",
       "       [[ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [ 0.04933679,  0.00352504,  0.04265995, -0.00057896,\n",
       "          0.03647229,  0.01322773, -0.01369426,  0.03341683,\n",
       "          0.03632704, -0.02339108],\n",
       "        [-0.01972367, -0.00328723,  0.0100074 , -0.0242569 ,\n",
       "         -0.0011251 ,  0.02024252,  0.00144215, -0.02671427,\n",
       "         -0.0062192 , -0.01905504],\n",
       "        [ 0.0332992 , -0.0384062 , -0.01839094,  0.00574167,\n",
       "         -0.00508986,  0.02084284, -0.02656484,  0.04844505,\n",
       "          0.04989931,  0.00884218],\n",
       "        [-0.0394449 , -0.04572257,  0.01711423,  0.04971423,\n",
       "         -0.01740722,  0.03069078, -0.03693045,  0.02564043,\n",
       "          0.00698708, -0.00032289],\n",
       "        [ 0.02756012,  0.03659394, -0.04558331,  0.04542447,\n",
       "         -0.03317118, -0.04099707,  0.02059417, -0.00535005,\n",
       "          0.02082281, -0.03791739]]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(embedded_docs)\n",
    "# each word is represented by 10 items in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 39ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.02640623,  0.04474883, -0.02724292,  0.04356681,  0.01628871,\n",
       "         0.01288262,  0.01359994,  0.04501638, -0.01337685, -0.04392293],\n",
       "       [ 0.02640623,  0.04474883, -0.02724292,  0.04356681,  0.01628871,\n",
       "         0.01288262,  0.01359994,  0.04501638, -0.01337685, -0.04392293],\n",
       "       [ 0.02640623,  0.04474883, -0.02724292,  0.04356681,  0.01628871,\n",
       "         0.01288262,  0.01359994,  0.04501638, -0.01337685, -0.04392293],\n",
       "       [ 0.02640623,  0.04474883, -0.02724292,  0.04356681,  0.01628871,\n",
       "         0.01288262,  0.01359994,  0.04501638, -0.01337685, -0.04392293],\n",
       "       [ 0.02893901, -0.02032731, -0.00309921, -0.04708452, -0.025536  ,\n",
       "        -0.02044545,  0.0142999 ,  0.0018507 ,  0.03366418,  0.01265682],\n",
       "       [-0.03737019,  0.01280436,  0.03970902, -0.02193613,  0.04111854,\n",
       "         0.01026414, -0.04655458, -0.03356011, -0.00992694, -0.03056669],\n",
       "       [ 0.03673179, -0.04071188, -0.00352743, -0.03266939,  0.00440998,\n",
       "        -0.02892788, -0.0104926 ,  0.00580841, -0.03222375,  0.04102645],\n",
       "       [ 0.03113868,  0.02154339, -0.01500081,  0.04533321,  0.00142758,\n",
       "         0.0461587 , -0.04495284, -0.01487942,  0.04571627, -0.02145296]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8 words per sentence\n",
    "# 10 features\n",
    "# ->\n",
    "# 8 subarray (one per word in the sentence)\n",
    "# 10 is the lenght of each subarray (one per feature)\n",
    "model.predict(embedded_docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_docs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
